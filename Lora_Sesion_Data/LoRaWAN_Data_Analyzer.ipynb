{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRaWAN Session Data Analyzer\n",
    "\n",
    "Dieses Notebook ermöglicht die interaktive Analyse von LoRaWAN Session Daten.\n",
    "\n",
    "## Datenstruktur\n",
    "Die CSV-Dateien enthalten folgende Spalten:\n",
    "- `timestamp`: Zeitstempel der Nachricht\n",
    "- `session_id`: Session-ID\n",
    "- `device_eui`: Device Identifier\n",
    "- `fcnt`: Frame Counter\n",
    "- `rssi_dbm`: Signal Strength (dBm)\n",
    "- `snr_db`: Signal-to-Noise Ratio (dB)\n",
    "- `spreading_factor`: LoRaWAN Spreading Factor\n",
    "- `frequency`: Übertragungsfrequenz\n",
    "- `device_lat/lon`: GPS-Koordinaten des Devices\n",
    "- `decoded_payload`: Sensor-Daten (JSON)\n",
    "- und weitere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "# Konfiguration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktionen für Datenanalyse\n",
    "\n",
    "def load_and_process_data(file_path):\n",
    "    \"\"\"Lädt und verarbeitet die CSV-Datei\"\"\"\n",
    "    df = pd.read_csv(file_path)  # CSV mit Komma-Separator\n",
    "    \n",
    "    # Datentyp-Konvertierungen\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['rssi_dbm'] = pd.to_numeric(df['rssi_dbm'], errors='coerce')\n",
    "    df['snr_db'] = pd.to_numeric(df['snr_db'], errors='coerce')\n",
    "    df['frequency'] = pd.to_numeric(df['frequency'], errors='coerce')\n",
    "    df['device_lat'] = pd.to_numeric(df['device_lat'], errors='coerce')\n",
    "    df['device_lon'] = pd.to_numeric(df['device_lon'], errors='coerce')\n",
    "    df['fcnt'] = pd.to_numeric(df['fcnt'], errors='coerce')\n",
    "    \n",
    "    # Parse JSON payload wenn vorhanden\n",
    "    if 'decoded_payload' in df.columns:\n",
    "        df['sensor_data'] = df['decoded_payload'].apply(parse_sensor_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_sensor_data(payload_str):\n",
    "    \"\"\"Parst die JSON-Payload und extrahiert Sensordaten\"\"\"\n",
    "    try:\n",
    "        if pd.isna(payload_str) or payload_str == '':\n",
    "            return None\n",
    "        \n",
    "        # Clean the JSON string\n",
    "        clean_payload = payload_str.replace('\"\"', '\"')\n",
    "        data = json.loads(clean_payload)\n",
    "        \n",
    "        result = {}\n",
    "        if 'd' in data and isinstance(data['d'], list) and len(data['d']) >= 2:\n",
    "            result['temperature'] = data['d'][0]\n",
    "            result['humidity'] = data['d'][1]\n",
    "        \n",
    "        if 'sf' in data:\n",
    "            result['sf_from_payload'] = data['sf']\n",
    "        \n",
    "        if 't' in data:\n",
    "            result['time_counter'] = data['t']\n",
    "        \n",
    "        return result\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "def get_available_files():\n",
    "    \"\"\"Zeigt verfügbare CSV-Dateien an\"\"\"\n",
    "    csv_files = glob(\"*.csv\")\n",
    "    csv_files.sort()\n",
    "    return csv_files\n",
    "\n",
    "def display_file_info(files):\n",
    "    \"\"\"Zeigt Informationen über verfügbare Dateien\"\"\"\n",
    "    print(\"Verfügbare LoRaWAN Session Dateien:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, file in enumerate(files):\n",
    "        file_size = os.path.getsize(file) / 1024  # KB\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(file))\n",
    "        print(f\"{i+1:2d}. {file}\")\n",
    "        print(f\"     Größe: {file_size:.1f} KB, Erstellt: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print()\n",
    "\n",
    "print(\"Hilfsfunktionen definiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige verfügbare Dateien\n",
    "available_files = get_available_files()\n",
    "display_file_info(available_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATEIAUSWAHL - Ändern Sie hier die Zahl entsprechend der gewünschten Datei\n",
    "selected_file_index = 8  # Ändern Sie diese Zahl (1-8) um eine andere Datei zu wählen\n",
    "\n",
    "if 1 <= selected_file_index <= len(available_files):\n",
    "    selected_file = available_files[selected_file_index - 1]\n",
    "    print(f\"Ausgewählte Datei: {selected_file}\")\n",
    "    \n",
    "    # Lade die Daten\n",
    "    df = load_and_process_data(selected_file)\n",
    "    print(f\"\\nDaten erfolgreich geladen: {len(df)} Datensätze\")\n",
    "else:\n",
    "    print(f\"Ungültige Auswahl! Bitte wählen Sie eine Zahl zwischen 1 und {len(available_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundlegende Datenübersicht\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENÜBERSICHT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Dateiname: {selected_file}\")\n",
    "print(f\"Anzahl Datensätze: {len(df)}\")\n",
    "print(f\"Zeitraum: {df['timestamp'].min()} bis {df['timestamp'].max()}\")\n",
    "print(f\"Dauer: {df['timestamp'].max() - df['timestamp'].min()}\")\n",
    "print(f\"Unique Devices: {df['device_eui'].nunique()}\")\n",
    "print(f\"Unique Sessions: {df['session_id'].nunique()}\")\n",
    "\n",
    "print(\"\\nSpalten im Datensatz:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Zeilen der Daten anzeigen\n",
    "print(\"ERSTE 5 DATENSÄTZE:\")\n",
    "print(\"=\" * 60)\n",
    "display_columns = ['timestamp', 'fcnt', 'rssi_dbm', 'snr_db', 'spreading_factor', 'frequency', 'device_lat', 'device_lon']\n",
    "df[display_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensordaten extrahieren und anzeigen\n",
    "sensor_data_expanded = pd.json_normalize(df['sensor_data'].dropna())\n",
    "\n",
    "if not sensor_data_expanded.empty:\n",
    "    print(\"SENSORDATEN (aus JSON Payload):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Anzahl Datensätze mit Sensordaten: {len(sensor_data_expanded)}\")\n",
    "    print(\"\\nSensordaten Statistiken:\")\n",
    "    print(sensor_data_expanded.describe())\n",
    "    \n",
    "    # Füge Sensordaten zum Haupt-DataFrame hinzu\n",
    "    df_sensor = df.dropna(subset=['sensor_data']).copy()\n",
    "    df_sensor = df_sensor.reset_index(drop=True)\n",
    "    sensor_data_expanded = sensor_data_expanded.reset_index(drop=True)\n",
    "    \n",
    "    for col in sensor_data_expanded.columns:\n",
    "        df_sensor[col] = sensor_data_expanded[col]\n",
    "    \n",
    "    print(\"\\nSensordaten wurden zum DataFrame hinzugefügt!\")\n",
    "else:\n",
    "    print(\"Keine Sensordaten gefunden.\")\n",
    "    df_sensor = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistische Analyse der Übertragungsqualität\n",
    "print(\"ÜBERTRAGUNGSQUALITÄT ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# RSSI Statistiken\n",
    "rssi_stats = df['rssi_dbm'].describe()\n",
    "print(\"RSSI (Received Signal Strength Indicator) Statistiken:\")\n",
    "print(rssi_stats)\n",
    "\n",
    "# SNR Statistiken\n",
    "snr_stats = df['snr_db'].describe()\n",
    "print(\"\\nSNR (Signal-to-Noise Ratio) Statistiken:\")\n",
    "print(snr_stats)\n",
    "\n",
    "# Spreading Factor Verteilung\n",
    "print(\"\\nSpreading Factor Verteilung:\")\n",
    "sf_counts = df['spreading_factor'].value_counts().sort_index()\n",
    "print(sf_counts)\n",
    "\n",
    "# Frequency Verteilung\n",
    "print(\"\\nFrequency Verteilung:\")\n",
    "freq_counts = df['frequency'].value_counts().sort_index()\n",
    "print(freq_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierungen erstellen\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(f'LoRaWAN Session Analysis - {selected_file}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. RSSI über Zeit\n",
    "axes[0, 0].plot(df['timestamp'], df['rssi_dbm'], 'b-', alpha=0.7, linewidth=1.5)\n",
    "axes[0, 0].set_title('RSSI über Zeit', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Zeit')\n",
    "axes[0, 0].set_ylabel('RSSI (dBm)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. SNR über Zeit\n",
    "axes[0, 1].plot(df['timestamp'], df['snr_db'], 'r-', alpha=0.7, linewidth=1.5)\n",
    "axes[0, 1].set_title('SNR über Zeit', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Zeit')\n",
    "axes[0, 1].set_ylabel('SNR (dB)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Spreading Factor Verteilung\n",
    "sf_counts.plot(kind='bar', ax=axes[1, 0], color='green', alpha=0.7)\n",
    "axes[1, 0].set_title('Spreading Factor Verteilung', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Spreading Factor')\n",
    "axes[1, 0].set_ylabel('Anzahl')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 4. RSSI vs SNR Scatter\n",
    "scatter = axes[1, 1].scatter(df['rssi_dbm'], df['snr_db'], c=df.index, cmap='viridis', alpha=0.7)\n",
    "axes[1, 1].set_title('RSSI vs SNR Correlation', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('RSSI (dBm)')\n",
    "axes[1, 1].set_ylabel('SNR (dB)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Zeitsequenz')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensordaten Visualisierung (falls verfügbar)\n",
    "if 'temperature' in df_sensor.columns and 'humidity' in df_sensor.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sensordaten Analyse', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Temperatur über Zeit\n",
    "    axes[0, 0].plot(df_sensor['timestamp'], df_sensor['temperature'], 'orange', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0, 0].set_title('Temperatur über Zeit', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Zeit')\n",
    "    axes[0, 0].set_ylabel('Temperatur (°C)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Feuchtigkeit über Zeit\n",
    "    axes[0, 1].plot(df_sensor['timestamp'], df_sensor['humidity'], 'cyan', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0, 1].set_title('Feuchtigkeit über Zeit', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Zeit')\n",
    "    axes[0, 1].set_ylabel('Feuchtigkeit (%)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Temperatur Histogramm\n",
    "    axes[1, 0].hist(df_sensor['temperature'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].set_title('Temperatur Verteilung', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Temperatur (°C)')\n",
    "    axes[1, 0].set_ylabel('Häufigkeit')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feuchtigkeit Histogramm\n",
    "    axes[1, 1].hist(df_sensor['humidity'], bins=20, alpha=0.7, color='cyan', edgecolor='black')\n",
    "    axes[1, 1].set_title('Feuchtigkeit Verteilung', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Feuchtigkeit (%)')\n",
    "    axes[1, 1].set_ylabel('Häufigkeit')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Sensordaten Statistiken\n",
    "    print(\"\\nSENSORDATEN STATISTIKEN:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Temperatur: {df_sensor['temperature'].mean():.2f}°C ± {df_sensor['temperature'].std():.2f}°C\")\n",
    "    print(f\"Bereich: {df_sensor['temperature'].min():.2f}°C - {df_sensor['temperature'].max():.2f}°C\")\n",
    "    print(f\"\\nFeuchtigkeit: {df_sensor['humidity'].mean():.2f}% ± {df_sensor['humidity'].std():.2f}%\")\n",
    "    print(f\"Bereich: {df_sensor['humidity'].min():.2f}% - {df_sensor['humidity'].max():.2f}%\")\n",
    "else:\n",
    "    print(\"Keine Sensordaten (Temperatur/Feuchtigkeit) verfügbar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweiterte Analyse: Korrelationen\n",
    "print(\"KORRELATIONSANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Numerische Spalten für Korrelation\n",
    "numeric_cols = ['rssi_dbm', 'snr_db', 'fcnt', 'frequency']\n",
    "if 'temperature' in df_sensor.columns:\n",
    "    numeric_cols.extend(['temperature', 'humidity'])\n",
    "\n",
    "# Korrelationsmatrix\n",
    "correlation_data = df_sensor[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'label': 'Korrelation'})\n",
    "plt.title('Korrelationsmatrix der Messwerte', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStärkste Korrelationen:\")\n",
    "# Finde die stärksten Korrelationen (außer Diagonal)\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation_data.columns)):\n",
    "    for j in range(i+1, len(correlation_data.columns)):\n",
    "        corr_value = correlation_data.iloc[i, j]\n",
    "        if not np.isnan(corr_value):\n",
    "            corr_pairs.append((correlation_data.columns[i], correlation_data.columns[j], corr_value))\n",
    "\n",
    "# Sortiere nach absoluter Korrelation\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "for i, (var1, var2, corr) in enumerate(corr_pairs[:5]):\n",
    "    print(f\"{i+1}. {var1} ↔ {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkqualitäts-Dashboard\n",
    "def analyze_network_quality(df):\n",
    "    \"\"\"Analysiert die Netzwerkqualität basierend auf RSSI und SNR\"\"\"\n",
    "    \n",
    "    # Qualitätskategorien definieren\n",
    "    def rssi_category(rssi):\n",
    "        if rssi >= -70:\n",
    "            return 'Excellent'\n",
    "        elif rssi >= -80:\n",
    "            return 'Good'\n",
    "        elif rssi >= -90:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    \n",
    "    def snr_category(snr):\n",
    "        if snr >= 10:\n",
    "            return 'Excellent'\n",
    "        elif snr >= 5:\n",
    "            return 'Good'\n",
    "        elif snr >= 0:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    \n",
    "    df['rssi_quality'] = df['rssi_dbm'].apply(rssi_category)\n",
    "    df['snr_quality'] = df['snr_db'].apply(snr_category)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analysiere Netzwerkqualität\n",
    "df_quality = analyze_network_quality(df.copy())\n",
    "\n",
    "# Visualisiere Qualitätsverteilung\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Netzwerkqualitäts-Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RSSI Qualitätsverteilung\n",
    "rssi_quality_counts = df_quality['rssi_quality'].value_counts()\n",
    "colors = ['green', 'orange', 'red', 'darkred']\n",
    "quality_order = ['Excellent', 'Good', 'Fair', 'Poor']\n",
    "rssi_quality_counts = rssi_quality_counts.reindex(quality_order, fill_value=0)\n",
    "\n",
    "axes[0].pie(rssi_quality_counts.values, labels=rssi_quality_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors[:len(rssi_quality_counts)], startangle=90)\n",
    "axes[0].set_title('RSSI Qualitätsverteilung', fontweight='bold')\n",
    "\n",
    "# SNR Qualitätsverteilung\n",
    "snr_quality_counts = df_quality['snr_quality'].value_counts()\n",
    "snr_quality_counts = snr_quality_counts.reindex(quality_order, fill_value=0)\n",
    "\n",
    "axes[1].pie(snr_quality_counts.values, labels=snr_quality_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors[:len(snr_quality_counts)], startangle=90)\n",
    "axes[1].set_title('SNR Qualitätsverteilung', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Qualitätsstatistiken ausgeben\n",
    "print(\"\\nNETZWERKQUALITÄT ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "print(\"RSSI Qualitätsverteilung:\")\n",
    "for quality, count in rssi_quality_counts.items():\n",
    "    percentage = (count / len(df_quality)) * 100\n",
    "    print(f\"  {quality}: {count} Nachrichten ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nSNR Qualitätsverteilung:\")\n",
    "for quality, count in snr_quality_counts.items():\n",
    "    percentage = (count / len(df_quality)) * 100\n",
    "    print(f\"  {quality}: {count} Nachrichten ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassung und Export-Optionen\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSEZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = {\n",
    "    'Dateiname': selected_file,\n",
    "    'Analysezeitpunkt': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Gesamtnachrichten': len(df),\n",
    "    'Zeitraum': f\"{df['timestamp'].min()} bis {df['timestamp'].max()}\",\n",
    "    'Durchschnittliche_RSSI': f\"{df['rssi_dbm'].mean():.2f} dBm\",\n",
    "    'Durchschnittliche_SNR': f\"{df['snr_db'].mean():.2f} dB\",\n",
    "    'Häufigster_SF': df['spreading_factor'].mode().iloc[0],\n",
    "    'Unique_Devices': df['device_eui'].nunique(),\n",
    "    'Qualität_Excellent_RSSI': f\"{(rssi_quality_counts.get('Excellent', 0) / len(df_quality) * 100):.1f}%\",\n",
    "    'Qualität_Excellent_SNR': f\"{(snr_quality_counts.get('Excellent', 0) / len(df_quality) * 100):.1f}%\"\n",
    "}\n",
    "\n",
    "if 'temperature' in df_sensor.columns:\n",
    "    summary.update({\n",
    "        'Durchschnittliche_Temperatur': f\"{df_sensor['temperature'].mean():.2f}°C\",\n",
    "        'Durchschnittliche_Feuchtigkeit': f\"{df_sensor['humidity'].mean():.2f}%\"\n",
    "    })\n",
    "\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key.replace('_', ' ')}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPORT-OPTIONEN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Sie können die Analyseergebnisse exportieren:\")\n",
    "print(\"1. DataFrame als CSV: df.to_csv('analysis_results.csv')\")\n",
    "print(\"2. Zusammenfassung als JSON: import json; json.dump(summary, open('summary.json', 'w'))\")\n",
    "print(\"3. Grafiken als PNG: plt.savefig('analysis_plots.png', dpi=300, bbox_inches='tight')\")\n",
    "\n",
    "print(\"\\nAnalyse abgeschlossen! 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionale Detailanalyse - Zeitreihenanalyse\n",
    "print(\"ZEITREIHENANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Zeitintervalle zwischen Nachrichten\n",
    "df_sorted = df.sort_values('timestamp')\n",
    "time_diffs = df_sorted['timestamp'].diff().dt.total_seconds()\n",
    "time_diffs = time_diffs.dropna()\n",
    "\n",
    "print(f\"Durchschnittliches Intervall zwischen Nachrichten: {time_diffs.mean():.2f} Sekunden\")\n",
    "print(f\"Minimum Intervall: {time_diffs.min():.2f} Sekunden\")\n",
    "print(f\"Maximum Intervall: {time_diffs.max():.2f} Sekunden\")\n",
    "\n",
    "# Visualisierung der Zeitintervalle\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(time_diffs, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Verteilung der Zeitintervalle zwischen Nachrichten', fontweight='bold')\n",
    "plt.xlabel('Zeitintervall (Sekunden)')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(time_diffs)), time_diffs, 'b-', alpha=0.7)\n",
    "plt.title('Zeitintervalle über die Session', fontweight='bold')\n",
    "plt.xlabel('Nachrichtennummer')\n",
    "plt.ylabel('Zeitintervall (Sekunden)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
