{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRaWAN Session Data Analyzer\n",
    "\n",
    "Dieses Notebook ermöglicht die interaktive Analyse von LoRaWAN Session Daten.\n",
    "\n",
    "## Datenstruktur\n",
    "Die CSV-Dateien enthalten folgende Spalten:\n",
    "- `timestamp`: Zeitstempel der Nachricht\n",
    "- `session_id`: Session-ID\n",
    "- `device_eui`: Device Identifier\n",
    "- `fcnt`: Frame Counter\n",
    "- `rssi_dbm`: Signal Strength (dBm)\n",
    "- `snr_db`: Signal-to-Noise Ratio (dB)\n",
    "- `spreading_factor`: LoRaWAN Spreading Factor\n",
    "- `frequency`: Übertragungsfrequenz\n",
    "- `device_lat/lon`: GPS-Koordinaten des Devices\n",
    "- `decoded_payload`: Sensor-Daten (JSON)\n",
    "- und weitere..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotheken erfolgreich importiert!\n"
     ]
    }
   ],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "# Konfiguration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Bibliotheken erfolgreich importiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hilfsfunktionen definiert!\n"
     ]
    }
   ],
   "source": [
    "# Funktionen für Datenanalyse\n",
    "\n",
    "def load_and_process_data(file_path):\n",
    "    \"\"\"Lädt und verarbeitet die CSV-Datei\"\"\"\n",
    "    df = pd.read_csv(file_path)  # CSV mit Komma-Separator\n",
    "    \n",
    "    # Datentyp-Konvertierungen\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['rssi_dbm'] = pd.to_numeric(df['rssi_dbm'], errors='coerce')\n",
    "    df['snr_db'] = pd.to_numeric(df['snr_db'], errors='coerce')\n",
    "    df['frequency'] = pd.to_numeric(df['frequency'], errors='coerce')\n",
    "    df['device_lat'] = pd.to_numeric(df['device_lat'], errors='coerce')\n",
    "    df['device_lon'] = pd.to_numeric(df['device_lon'], errors='coerce')\n",
    "    df['fcnt'] = pd.to_numeric(df['fcnt'], errors='coerce')\n",
    "    \n",
    "    # Parse JSON payload wenn vorhanden\n",
    "    if 'decoded_payload' in df.columns:\n",
    "        df['sensor_data'] = df['decoded_payload'].apply(parse_sensor_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_sensor_data(payload_str):\n",
    "    \"\"\"Parst die JSON-Payload und extrahiert Sensordaten\"\"\"\n",
    "    try:\n",
    "        if pd.isna(payload_str) or payload_str == '':\n",
    "            return None\n",
    "        \n",
    "        # Clean the JSON string\n",
    "        clean_payload = payload_str.replace('\"\"', '\"')\n",
    "        data = json.loads(clean_payload)\n",
    "        \n",
    "        result = {}\n",
    "        if 'd' in data and isinstance(data['d'], list) and len(data['d']) >= 2:\n",
    "            result['temperature'] = data['d'][0]\n",
    "            result['humidity'] = data['d'][1]\n",
    "        \n",
    "        if 'sf' in data:\n",
    "            result['sf_from_payload'] = data['sf']\n",
    "        \n",
    "        if 't' in data:\n",
    "            result['time_counter'] = data['t']\n",
    "        \n",
    "        return result\n",
    "    except (json.JSONDecodeError, KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "def get_available_files():\n",
    "    \"\"\"Zeigt verfügbare CSV-Dateien an\"\"\"\n",
    "    csv_files = glob(\"*.csv\")\n",
    "    csv_files.sort()\n",
    "    return csv_files\n",
    "\n",
    "def display_file_info(files):\n",
    "    \"\"\"Zeigt Informationen über verfügbare Dateien\"\"\"\n",
    "    print(\"Verfügbare LoRaWAN Session Dateien:\")\n",
    "    print(\"=\" * 50)\n",
    "    for i, file in enumerate(files):\n",
    "        file_size = os.path.getsize(file) / 1024  # KB\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(file))\n",
    "        print(f\"{i+1:2d}. {file}\")\n",
    "        print(f\"     Größe: {file_size:.1f} KB, Erstellt: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print()\n",
    "\n",
    "print(\"Hilfsfunktionen definiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verfügbare LoRaWAN Session Dateien:\n",
      "==================================================\n",
      " 1. lorawan_data.csv\n",
      "     Größe: 14.2 KB, Erstellt: 2025-07-07 23:18:09\n",
      "\n",
      " 2. lorawan_session_20250707_204252_526570b6.csv\n",
      "     Größe: 0.6 KB, Erstellt: 2025-07-07 23:18:09\n",
      "\n",
      " 3. lorawan_session_20250707_204441_af09a252 copy.csv\n",
      "     Größe: 0.3 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 4. lorawan_session_20250707_210235_7f9c8028 copy.csv\n",
      "     Größe: 0.9 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 5. lorawan_session_20250707_210306_bcd879bb copy.csv\n",
      "     Größe: 0.6 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 6. lorawan_session_20250707_211812_9c7e7812 copy.csv\n",
      "     Größe: 0.6 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 7. lorawan_session_20250707_211833_154b5404 copy.csv\n",
      "     Größe: 0.3 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 8. lorawan_session_20250707_211906_f1583e36 copy.csv\n",
      "     Größe: 0.0 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      " 9. lorawan_session_20250707_212614_8d65ca84 copy.csv\n",
      "     Größe: 9.4 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      "10. lorawan_session_20250707_213340_9deb856e copy.csv\n",
      "     Größe: 12.6 KB, Erstellt: 2025-07-08 12:29:59\n",
      "\n",
      "11. lorawan_session_20250707_221922_6119ec60.csv\n",
      "     Größe: 0.3 KB, Erstellt: 2025-07-10 16:33:30\n",
      "\n",
      "12. lorawan_session_20250707_221949_ca42b3c2.csv\n",
      "     Größe: 202.2 KB, Erstellt: 2025-07-10 16:33:30\n",
      "\n",
      "13. lorawan_session_20250707_235158_a9a2044d.csv\n",
      "     Größe: 13.3 KB, Erstellt: 2025-07-10 16:33:30\n",
      "\n",
      "14. lorawan_session_20250715_134658_7ebbbea9.csv\n",
      "     Größe: 8.4 KB, Erstellt: 2025-07-15 16:40:28\n",
      "\n",
      "15. lorawan_session_20250715_141939_a7304177.csv\n",
      "     Größe: 2.3 KB, Erstellt: 2025-07-15 16:40:28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zeige verfügbare Dateien\n",
    "available_files = get_available_files()\n",
    "display_file_info(available_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausgewählte Datei: lorawan_session_20250707_211906_f1583e36 copy.csv\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAusgewählte Datei: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Lade die Daten\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     df = \u001b[43mload_and_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDaten erfolgreich geladen: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Datensätze\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_and_process_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_and_process_data\u001b[39m(file_path):\n\u001b[32m      4\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Lädt und verarbeitet die CSV-Datei\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# CSV mit Komma-Separator\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Datentyp-Konvertierungen\u001b[39;00m\n\u001b[32m      8\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# DATEIAUSWAHL - Ändern Sie hier die Zahl entsprechend der gewünschten Datei\n",
    "selected_file_index = 8  # Ändern Sie diese Zahl (1-8) um eine andere Datei zu wählen\n",
    "\n",
    "if 1 <= selected_file_index <= len(available_files):\n",
    "    selected_file = available_files[selected_file_index - 1]\n",
    "    print(f\"Ausgewählte Datei: {selected_file}\")\n",
    "    \n",
    "    # Lade die Daten\n",
    "    df = load_and_process_data(selected_file)\n",
    "    print(f\"\\nDaten erfolgreich geladen: {len(df)} Datensätze\")\n",
    "else:\n",
    "    print(f\"Ungültige Auswahl! Bitte wählen Sie eine Zahl zwischen 1 und {len(available_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundlegende Datenübersicht\n",
    "print(\"=\" * 60)\n",
    "print(\"DATENÜBERSICHT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Dateiname: {selected_file}\")\n",
    "print(f\"Anzahl Datensätze: {len(df)}\")\n",
    "print(f\"Zeitraum: {df['timestamp'].min()} bis {df['timestamp'].max()}\")\n",
    "print(f\"Dauer: {df['timestamp'].max() - df['timestamp'].min()}\")\n",
    "print(f\"Unique Devices: {df['device_eui'].nunique()}\")\n",
    "print(f\"Unique Sessions: {df['session_id'].nunique()}\")\n",
    "\n",
    "print(\"\\nSpalten im Datensatz:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste Zeilen der Daten anzeigen\n",
    "print(\"ERSTE 5 DATENSÄTZE:\")\n",
    "print(\"=\" * 60)\n",
    "display_columns = ['timestamp', 'fcnt', 'rssi_dbm', 'snr_db', 'spreading_factor', 'frequency', 'device_lat', 'device_lon']\n",
    "df[display_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensordaten extrahieren und anzeigen\n",
    "sensor_data_expanded = pd.json_normalize(df['sensor_data'].dropna())\n",
    "\n",
    "if not sensor_data_expanded.empty:\n",
    "    print(\"SENSORDATEN (aus JSON Payload):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Anzahl Datensätze mit Sensordaten: {len(sensor_data_expanded)}\")\n",
    "    print(\"\\nSensordaten Statistiken:\")\n",
    "    print(sensor_data_expanded.describe())\n",
    "    \n",
    "    # Füge Sensordaten zum Haupt-DataFrame hinzu\n",
    "    df_sensor = df.dropna(subset=['sensor_data']).copy()\n",
    "    df_sensor = df_sensor.reset_index(drop=True)\n",
    "    sensor_data_expanded = sensor_data_expanded.reset_index(drop=True)\n",
    "    \n",
    "    for col in sensor_data_expanded.columns:\n",
    "        df_sensor[col] = sensor_data_expanded[col]\n",
    "    \n",
    "    print(\"\\nSensordaten wurden zum DataFrame hinzugefügt!\")\n",
    "else:\n",
    "    print(\"Keine Sensordaten gefunden.\")\n",
    "    df_sensor = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistische Analyse der Übertragungsqualität\n",
    "print(\"ÜBERTRAGUNGSQUALITÄT ANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# RSSI Statistiken\n",
    "rssi_stats = df['rssi_dbm'].describe()\n",
    "print(\"RSSI (Received Signal Strength Indicator) Statistiken:\")\n",
    "print(rssi_stats)\n",
    "\n",
    "# SNR Statistiken\n",
    "snr_stats = df['snr_db'].describe()\n",
    "print(\"\\nSNR (Signal-to-Noise Ratio) Statistiken:\")\n",
    "print(snr_stats)\n",
    "\n",
    "# Spreading Factor Verteilung\n",
    "print(\"\\nSpreading Factor Verteilung:\")\n",
    "sf_counts = df['spreading_factor'].value_counts().sort_index()\n",
    "print(sf_counts)\n",
    "\n",
    "# Frequency Verteilung\n",
    "print(\"\\nFrequency Verteilung:\")\n",
    "freq_counts = df['frequency'].value_counts().sort_index()\n",
    "print(freq_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierungen erstellen\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(f'LoRaWAN Session Analysis - {selected_file}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. RSSI über Zeit\n",
    "axes[0, 0].plot(df['timestamp'], df['rssi_dbm'], 'b-', alpha=0.7, linewidth=1.5)\n",
    "axes[0, 0].set_title('RSSI über Zeit', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Zeit')\n",
    "axes[0, 0].set_ylabel('RSSI (dBm)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. SNR über Zeit\n",
    "axes[0, 1].plot(df['timestamp'], df['snr_db'], 'r-', alpha=0.7, linewidth=1.5)\n",
    "axes[0, 1].set_title('SNR über Zeit', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Zeit')\n",
    "axes[0, 1].set_ylabel('SNR (dB)')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Spreading Factor Verteilung\n",
    "sf_counts.plot(kind='bar', ax=axes[1, 0], color='green', alpha=0.7)\n",
    "axes[1, 0].set_title('Spreading Factor Verteilung', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Spreading Factor')\n",
    "axes[1, 0].set_ylabel('Anzahl')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 4. RSSI vs SNR Scatter\n",
    "scatter = axes[1, 1].scatter(df['rssi_dbm'], df['snr_db'], c=df.index, cmap='viridis', alpha=0.7)\n",
    "axes[1, 1].set_title('RSSI vs SNR Correlation', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('RSSI (dBm)')\n",
    "axes[1, 1].set_ylabel('SNR (dB)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[1, 1], label='Zeitsequenz')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensordaten Visualisierung (falls verfügbar)\n",
    "if 'temperature' in df_sensor.columns and 'humidity' in df_sensor.columns:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Sensordaten Analyse', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Temperatur über Zeit\n",
    "    axes[0, 0].plot(df_sensor['timestamp'], df_sensor['temperature'], 'orange', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0, 0].set_title('Temperatur über Zeit', fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Zeit')\n",
    "    axes[0, 0].set_ylabel('Temperatur (°C)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Feuchtigkeit über Zeit\n",
    "    axes[0, 1].plot(df_sensor['timestamp'], df_sensor['humidity'], 'cyan', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0, 1].set_title('Feuchtigkeit über Zeit', fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Zeit')\n",
    "    axes[0, 1].set_ylabel('Feuchtigkeit (%)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Temperatur Histogramm\n",
    "    axes[1, 0].hist(df_sensor['temperature'], bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 0].set_title('Temperatur Verteilung', fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Temperatur (°C)')\n",
    "    axes[1, 0].set_ylabel('Häufigkeit')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feuchtigkeit Histogramm\n",
    "    axes[1, 1].hist(df_sensor['humidity'], bins=20, alpha=0.7, color='cyan', edgecolor='black')\n",
    "    axes[1, 1].set_title('Feuchtigkeit Verteilung', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Feuchtigkeit (%)')\n",
    "    axes[1, 1].set_ylabel('Häufigkeit')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Sensordaten Statistiken\n",
    "    print(\"\\nSENSORDATEN STATISTIKEN:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Temperatur: {df_sensor['temperature'].mean():.2f}°C ± {df_sensor['temperature'].std():.2f}°C\")\n",
    "    print(f\"Bereich: {df_sensor['temperature'].min():.2f}°C - {df_sensor['temperature'].max():.2f}°C\")\n",
    "    print(f\"\\nFeuchtigkeit: {df_sensor['humidity'].mean():.2f}% ± {df_sensor['humidity'].std():.2f}%\")\n",
    "    print(f\"Bereich: {df_sensor['humidity'].min():.2f}% - {df_sensor['humidity'].max():.2f}%\")\n",
    "else:\n",
    "    print(\"Keine Sensordaten (Temperatur/Feuchtigkeit) verfügbar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erweiterte Analyse: Korrelationen\n",
    "print(\"KORRELATIONSANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Numerische Spalten für Korrelation\n",
    "numeric_cols = ['rssi_dbm', 'snr_db', 'fcnt', 'frequency']\n",
    "if 'temperature' in df_sensor.columns:\n",
    "    numeric_cols.extend(['temperature', 'humidity'])\n",
    "\n",
    "# Korrelationsmatrix\n",
    "correlation_data = df_sensor[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'label': 'Korrelation'})\n",
    "plt.title('Korrelationsmatrix der Messwerte', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStärkste Korrelationen:\")\n",
    "# Finde die stärksten Korrelationen (außer Diagonal)\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation_data.columns)):\n",
    "    for j in range(i+1, len(correlation_data.columns)):\n",
    "        corr_value = correlation_data.iloc[i, j]\n",
    "        if not np.isnan(corr_value):\n",
    "            corr_pairs.append((correlation_data.columns[i], correlation_data.columns[j], corr_value))\n",
    "\n",
    "# Sortiere nach absoluter Korrelation\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "for i, (var1, var2, corr) in enumerate(corr_pairs[:5]):\n",
    "    print(f\"{i+1}. {var1} ↔ {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkqualitäts-Dashboard\n",
    "def analyze_network_quality(df):\n",
    "    \"\"\"Analysiert die Netzwerkqualität basierend auf RSSI und SNR\"\"\"\n",
    "    \n",
    "    # Qualitätskategorien definieren\n",
    "    def rssi_category(rssi):\n",
    "        if rssi >= -70:\n",
    "            return 'Excellent'\n",
    "        elif rssi >= -80:\n",
    "            return 'Good'\n",
    "        elif rssi >= -90:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    \n",
    "    def snr_category(snr):\n",
    "        if snr >= 10:\n",
    "            return 'Excellent'\n",
    "        elif snr >= 5:\n",
    "            return 'Good'\n",
    "        elif snr >= 0:\n",
    "            return 'Fair'\n",
    "        else:\n",
    "            return 'Poor'\n",
    "    \n",
    "    df['rssi_quality'] = df['rssi_dbm'].apply(rssi_category)\n",
    "    df['snr_quality'] = df['snr_db'].apply(snr_category)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Analysiere Netzwerkqualität\n",
    "df_quality = analyze_network_quality(df.copy())\n",
    "\n",
    "# Visualisiere Qualitätsverteilung\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Netzwerkqualitäts-Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# RSSI Qualitätsverteilung\n",
    "rssi_quality_counts = df_quality['rssi_quality'].value_counts()\n",
    "colors = ['green', 'orange', 'red', 'darkred']\n",
    "quality_order = ['Excellent', 'Good', 'Fair', 'Poor']\n",
    "rssi_quality_counts = rssi_quality_counts.reindex(quality_order, fill_value=0)\n",
    "\n",
    "axes[0].pie(rssi_quality_counts.values, labels=rssi_quality_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors[:len(rssi_quality_counts)], startangle=90)\n",
    "axes[0].set_title('RSSI Qualitätsverteilung', fontweight='bold')\n",
    "\n",
    "# SNR Qualitätsverteilung\n",
    "snr_quality_counts = df_quality['snr_quality'].value_counts()\n",
    "snr_quality_counts = snr_quality_counts.reindex(quality_order, fill_value=0)\n",
    "\n",
    "axes[1].pie(snr_quality_counts.values, labels=snr_quality_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors[:len(snr_quality_counts)], startangle=90)\n",
    "axes[1].set_title('SNR Qualitätsverteilung', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Qualitätsstatistiken ausgeben\n",
    "print(\"\\nNETZWERKQUALITÄT ZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 60)\n",
    "print(\"RSSI Qualitätsverteilung:\")\n",
    "for quality, count in rssi_quality_counts.items():\n",
    "    percentage = (count / len(df_quality)) * 100\n",
    "    print(f\"  {quality}: {count} Nachrichten ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nSNR Qualitätsverteilung:\")\n",
    "for quality, count in snr_quality_counts.items():\n",
    "    percentage = (count / len(df_quality)) * 100\n",
    "    print(f\"  {quality}: {count} Nachrichten ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassung und Export-Optionen\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSEZUSAMMENFASSUNG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = {\n",
    "    'Dateiname': selected_file,\n",
    "    'Analysezeitpunkt': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Gesamtnachrichten': len(df),\n",
    "    'Zeitraum': f\"{df['timestamp'].min()} bis {df['timestamp'].max()}\",\n",
    "    'Durchschnittliche_RSSI': f\"{df['rssi_dbm'].mean():.2f} dBm\",\n",
    "    'Durchschnittliche_SNR': f\"{df['snr_db'].mean():.2f} dB\",\n",
    "    'Häufigster_SF': df['spreading_factor'].mode().iloc[0],\n",
    "    'Unique_Devices': df['device_eui'].nunique(),\n",
    "    'Qualität_Excellent_RSSI': f\"{(rssi_quality_counts.get('Excellent', 0) / len(df_quality) * 100):.1f}%\",\n",
    "    'Qualität_Excellent_SNR': f\"{(snr_quality_counts.get('Excellent', 0) / len(df_quality) * 100):.1f}%\"\n",
    "}\n",
    "\n",
    "if 'temperature' in df_sensor.columns:\n",
    "    summary.update({\n",
    "        'Durchschnittliche_Temperatur': f\"{df_sensor['temperature'].mean():.2f}°C\",\n",
    "        'Durchschnittliche_Feuchtigkeit': f\"{df_sensor['humidity'].mean():.2f}%\"\n",
    "    })\n",
    "\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key.replace('_', ' ')}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPORT-OPTIONEN\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Sie können die Analyseergebnisse exportieren:\")\n",
    "print(\"1. DataFrame als CSV: df.to_csv('analysis_results.csv')\")\n",
    "print(\"2. Zusammenfassung als JSON: import json; json.dump(summary, open('summary.json', 'w'))\")\n",
    "print(\"3. Grafiken als PNG: plt.savefig('analysis_plots.png', dpi=300, bbox_inches='tight')\")\n",
    "\n",
    "print(\"\\nAnalyse abgeschlossen! 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionale Detailanalyse - Zeitreihenanalyse\n",
    "print(\"ZEITREIHENANALYSE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Zeitintervalle zwischen Nachrichten\n",
    "df_sorted = df.sort_values('timestamp')\n",
    "time_diffs = df_sorted['timestamp'].diff().dt.total_seconds()\n",
    "time_diffs = time_diffs.dropna()\n",
    "\n",
    "print(f\"Durchschnittliches Intervall zwischen Nachrichten: {time_diffs.mean():.2f} Sekunden\")\n",
    "print(f\"Minimum Intervall: {time_diffs.min():.2f} Sekunden\")\n",
    "print(f\"Maximum Intervall: {time_diffs.max():.2f} Sekunden\")\n",
    "\n",
    "# Visualisierung der Zeitintervalle\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(time_diffs, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Verteilung der Zeitintervalle zwischen Nachrichten', fontweight='bold')\n",
    "plt.xlabel('Zeitintervall (Sekunden)')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(time_diffs)), time_diffs, 'b-', alpha=0.7)\n",
    "plt.title('Zeitintervalle über die Session', fontweight='bold')\n",
    "plt.xlabel('Nachrichtennummer')\n",
    "plt.ylabel('Zeitintervall (Sekunden)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
